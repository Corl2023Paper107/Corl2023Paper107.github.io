<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

    <title>Exploitation-Guided Exploration for Semantic Embodied Navigation</title>
  </head>
  <body>
  	<div style="text-align:center;">
	    <div id="intro" style="width: 100%; padding:40px; text-align:center;">
	    <h1><a style="color:#191919">Exploitation-Guided Exploration for Semantic Embodied Navigation</a></h1>
	    </div>

	    <div class="container" >
		  <div class="row">		
		    <div class="col-sm">
		      <h4> Anonymous Authors </h4> 
		    </div>
		  </div>


	    <div class="row">
	  	<div class="col-lg">
	   	    <h4> In submission to CoRL 2023 </h4>
	        </div>
	    </div>

            <br><br>
		  
	    <!--<div class="row">
		  <div class="col-lg">
		    <center><h2>
            <a href="https://google.com"> [Anonymous Code] </a>
            </h2></center> 
		  </div>
	    </div>-->
		

		  <!--
	    <div class="row">
	  	<div class="col-lg">
	  	<img src="./images/workflow.png" class="img-fluid" style="width:900px;">
	  	</div>
	    </div>-->

	    <br><br>

	    <div class="row">
	  	<div class="col-sm">
	  		<h2> Abstract </h2>
	  	</div>
	    </div>

	    <div class="row">
	  	<div style="font-size:16px"><p align="justify">
In the recent progress in embodied navigation and sim-to-robot transfer, modular policies have emerged as a de facto framework. However, there is more to compositionality beyond the decomposition of the learning load into separate exploration and exploitation phases. In this work, we investigate how the syntactical combination of these modules can be enhanced. Particularly, we devise Exploitation-Guided Exploration (or XGX) where we combine these modules in a novel and intuitive manner. We allow the exploitation module to take over in the deterministic final steps of navigation when the goal is visible. Crucially, in XGX it teacher-forces the exploration module and continues driving an overridden policy optimization. With this guidance and a simple and effective choice of exploitation module, XGX improves the state-of-the-art on the challenging object navigation task from 70% to 76%. Along with better accuracy, through targeted analysis, we show that it is more efficient at goal-conditioned exploration. Finally, we show sim-to-real transfer to robot hardware where trends hold in favor of XGX.
	  	</p>
	  	</div>
        </div>
        <hr>
	    <br><br>
	    <div class="row">
	  	<div class="col-sm">
	  		<h2> Robot Morphology </h2>
	  	</div>
	    </div>
	    <div class="row">
	  	<div class="col-lg">
	  	<img src="https://corl2023paper107.github.io/images/robot.png" class="img-fluid" style="width:800px;">
	  	</div>
	    </div>
	    <br>
	    
	    <div class="row">
	  	<div style="font-size:16px"><p align="justify">
    <b>Hardware specification:</b> Key features in the wheeled robot:<br>
    (1) Four independent trains<br>
    (2) LIDAR for autonomy and mappin<br>
    (3) Zero radius turns help us in the policy transfer. <br><br>
    
    We utilize an economical, widely-used RGB camera (Intel® RealSense™ D435i), a 2D LIDAR (Hokuyo® UST-10LX), that in conjunction with RTAB-MAP helps localize the agent in the real-world (analogous to the ‘GPS+Compass sensor’ in AIHabitat). At the end of every episode, the map created by RTAB-MAP is deleted. Following success in robot navigation and locomotion research, we realize the low-level actuation using Model Predictive Control.
    <div class="row">
	<div class="col-lg">
	    <img src="https://corl2023paper107.github.io/images/goals.png" class="img-fluid" style="width:600px;">
	</div>
    </div>
        Goal categories are {Couch, TV, Chair} (overlapping with HM3D objects in AIHabitat). 
    <br><br>
    <div class="row">
  	<div class="col-lg">
  	<img src="https://corl2023paper107.github.io/images/robotInEnv.png" class="img-fluid" style="width:900px;">
  	</div>
    </div>



	  	</div>
        </div>
        <hr>
	    <br>
	    
	    <div class="row">
	  	<div class="col-lg">
	  		<h2>Qualitative Rollouts</h2><br>
			<center>
			<h3>Transfer with Simulation Parameters Fails!</h3>
			When transferring polcies from sim-to-real, we found that using the simuation parameters that don't match the robot's camera and phyiscal parameters causes the robot to fail. In the following rollout, the agent with the simulator's default camera and physical parameters fails to stop at a chair!
			<img src="https://corl2023paper107.github.io/images/roll1.png" class="img-fluid" style="width:1200px;"><br><br><br>
			<h3>Retraining with Robot Parameters Improves Navigation Performance</h3>
            After retraining the policy in simulation with the parameters corresponding to the real world robot, the agent is able to complete object-goal navigation tasks. In the following rollout the agent reaches a TV that was 12 meters away from the starting location.
			<img src="https://corl2023paper107.github.io/images/roll2.png" class="img-fluid" style="width:1200px;">
			</center>
            </div>
	    </div>        		
	<br><br>

	</div>
	</div>
        <br><br>


	<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>

   <!--     <footer>	  		
		<p align="center">
		 Website adapted from <a href="https://ioujenliu.github.io/SemanticTracklets/">Iou-Jen</a>, <a href="https://jonbarron.info/">Jon Barron </a> and <a href="https://github.com/leonidk/new_website"> Leonid Keselman </a>.
	</footer> -->

  </body>


</html>
